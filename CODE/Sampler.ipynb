{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Vocabulary.ipynb\n",
      "importing Jupyter notebook from BeamSearch.ipynb\n",
      "importing Jupyter notebook from Utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from Vocabulary import *\n",
    "from BeamSearch import *\n",
    "from Utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler:\n",
    "    def __init__(self, voc_path, input_shape, output_size, context_length):\n",
    "        self.voc = Vocabulary()\n",
    "        self.voc.retrieve(voc_path)\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        self.output_size = output_size\n",
    "\n",
    "        print(\"Vocabulary size: {}\".format(self.voc.size))\n",
    "        print(\"Input shape: {}\".format(self.input_shape))\n",
    "        print(\"Output size: {}\".format(self.output_size))\n",
    "\n",
    "        self.context_length = context_length\n",
    "\n",
    "    def predict_greedy(self, model, input_img, require_sparse_label=True, sequence_length=150, verbose=False):\n",
    "        current_context = [self.voc.vocabulary[PLACEHOLDER]] * (self.context_length - 1)\n",
    "        current_context.append(self.voc.vocabulary[START_TOKEN])\n",
    "        if require_sparse_label:\n",
    "            current_context = Utils.sparsify(current_context, self.output_size)\n",
    "\n",
    "        predictions = START_TOKEN\n",
    "        out_probas = []\n",
    "\n",
    "        for i in range(0, sequence_length):\n",
    "            if verbose:\n",
    "                print(\"predicting {}/{}...\".format(i, sequence_length))\n",
    "\n",
    "            probas = model.predict(input_img, np.array([current_context]))\n",
    "            prediction = np.argmax(probas)\n",
    "            out_probas.append(probas)\n",
    "\n",
    "            new_context = []\n",
    "            for j in range(1, self.context_length):\n",
    "                new_context.append(current_context[j])\n",
    "\n",
    "            if require_sparse_label:\n",
    "                sparse_label = np.zeros(self.output_size)\n",
    "                sparse_label[prediction] = 1\n",
    "                new_context.append(sparse_label)\n",
    "            else:\n",
    "                new_context.append(prediction)\n",
    "\n",
    "            current_context = new_context\n",
    "\n",
    "            predictions += self.voc.token_lookup[prediction]\n",
    "\n",
    "            if self.voc.token_lookup[prediction] == END_TOKEN:\n",
    "                break\n",
    "\n",
    "        return predictions, out_probas\n",
    "\n",
    "    def recursive_beam_search(self, model, input_img, current_context, beam, current_node, sequence_length):\n",
    "        probas = model.predict(input_img, np.array([current_context]))\n",
    "\n",
    "        predictions = []\n",
    "        for i in range(0, len(probas)):\n",
    "            predictions.append((i, probas[i], probas))\n",
    "\n",
    "        nodes = []\n",
    "        for i in range(0, len(predictions)):\n",
    "            prediction = predictions[i][0]\n",
    "            score = predictions[i][1]\n",
    "            output_probas = predictions[i][2]\n",
    "            nodes.append(Node(prediction, score, output_probas))\n",
    "\n",
    "        beam.add_nodes(current_node, nodes)\n",
    "\n",
    "        if beam.is_valid():\n",
    "            beam.prune_leaves()\n",
    "            if sequence_length == 1 or self.voc.token_lookup[beam.root.max_child().key] == END_TOKEN:\n",
    "                return\n",
    "\n",
    "            for node in beam.get_leaves():\n",
    "                prediction = node.key\n",
    "\n",
    "                new_context = []\n",
    "                for j in range(1, self.context_length):\n",
    "                    new_context.append(current_context[j])\n",
    "                sparse_label = np.zeros(self.output_size)\n",
    "                sparse_label[prediction] = 1\n",
    "                new_context.append(sparse_label)\n",
    "\n",
    "                self.recursive_beam_search(model, input_img, new_context, beam, node, sequence_length - 1)\n",
    "\n",
    "    def predict_beam_search(self, model, input_img, beam_width=3, require_sparse_label=True, sequence_length=150):\n",
    "        predictions = START_TOKEN\n",
    "        out_probas = []\n",
    "\n",
    "        current_context = [self.voc.vocabulary[PLACEHOLDER]] * (self.context_length - 1)\n",
    "        current_context.append(self.voc.vocabulary[START_TOKEN])\n",
    "        if require_sparse_label:\n",
    "            current_context = Utils.sparsify(current_context, self.output_size)\n",
    "\n",
    "        beam = BeamSearch(beam_width=beam_width)\n",
    "\n",
    "        self.recursive_beam_search(model, input_img, current_context, beam, beam.root, sequence_length)\n",
    "\n",
    "        predicted_sequence, probas_sequence = beam.search()\n",
    "\n",
    "        for k in range(0, len(predicted_sequence)):\n",
    "            prediction = predicted_sequence[k]\n",
    "            probas = probas_sequence[k]\n",
    "            out_probas.append(probas)\n",
    "\n",
    "            predictions += self.voc.token_lookup[prediction]\n",
    "\n",
    "        return predictions, out_probas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
